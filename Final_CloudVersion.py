import ctypes
import streamlit as st
import pandas as pd
import numpy as np
import librosa
from scipy.stats import skew, kurtosis
from sklearn.preprocessing import RobustScaler, LabelEncoder
from sklearn.ensemble import AdaBoostClassifier
import matplotlib.pyplot as plt
from PIL import Image
import os
import pygame
import soundfile as sf


IS_CLOUD = True

def toggle_leds(state):
    if IS_CLOUD:
        return  # Disabled in cloud
    user32 = ctypes.WinDLL("user32")
    VK_CAPITAL = 0x14
    VK_NUMLOCK = 0x90

    if (user32.GetKeyState(VK_CAPITAL) & 1) != state:
        user32.keybd_event(VK_CAPITAL, 0, 0, 0)
        user32.keybd_event(VK_CAPITAL, 0, 2, 0)

    if (user32.GetKeyState(VK_NUMLOCK) & 1) != state:
        user32.keybd_event(VK_NUMLOCK, 0, 0, 0)
        user32.keybd_event(VK_NUMLOCK, 0, 2, 0)

def play_audio_feedback(text):
    if IS_CLOUD:
        return  # Disabled in cloud
    try:
        from gtts import gTTS
        tts = gTTS(text=text, lang="en")
        tts.save("feedback.mp3")

        pygame.mixer.init()
        pygame.mixer.music.load("feedback.mp3")
        pygame.mixer.music.play()
        while pygame.mixer.music.get_busy():
            pass

        pygame.mixer.quit()
        os.remove("feedback.mp3")
    except:
        pass


def load_dataset():
    dataset = pd.read_csv("Book1.csv")
    dataset = dataset.drop(columns=["Unnamed: 0"], errors="ignore")
    return dataset


def extract_features(signal, sample_rate):
    magnitude = np.abs(signal)
    power = np.square(signal)
    mfcc = librosa.feature.mfcc(y=signal, sr=sample_rate, n_mfcc=13)

    return pd.DataFrame([{
        "M_mean": np.mean(magnitude),
        "M_variance": np.var(magnitude),
        "M_skewness": skew(magnitude),
        "M_kurtosis": kurtosis(magnitude),
        "P_mean": np.mean(power),
        "P_variance": np.var(power),
        "P_skewness": skew(power),
        "P_kurtosis": kurtosis(power),
        "MFCC_Mean": np.mean(mfcc),
        "MFCC_Variance": np.var(mfcc),
        "Delta_Mean": np.mean(librosa.feature.delta(mfcc)),
        "Delta_Variance": np.var(librosa.feature.delta(mfcc)),
        "DoubleDelta_Mean": np.mean(librosa.feature.delta(mfcc, order=2)),
        "DoubleDelta_Variance": np.var(librosa.feature.delta(mfcc, order=2))
    }])


def train_classifier(dataset):
    scaler = RobustScaler()
    le = LabelEncoder()

    dataset.iloc[:, :-1] = scaler.fit_transform(dataset.iloc[:, :-1])
    dataset["Class"] = le.fit_transform(dataset["Class"])

    clf = AdaBoostClassifier(n_estimators=50, random_state=89, learning_rate=0.5)
    clf.fit(dataset.iloc[:, :-1], dataset["Class"])

    return clf, scaler, le

st.title("Voice Veritas: Truth in Voices")

st.sidebar.title("Navigation")
section = st.sidebar.radio("Go to", ["Home", "Classify Voice", "Explore Dataset"])

if section == "Home":
    st.subheader("Welcome")

    st.info(
        " Deployment Note:\n\n"
        "- Audio file upload is used in cloud deployment.\n"
        "- Real-time microphone input, keyboard LED control, and speaker feedback "
        "are supported **only during local execution**."
    )

    img = Image.open("aiandhuman.jpg")
    st.image(img, caption="AI vs Human Voice", width=300)

elif section == "Classify Voice":
    st.subheader("Classify Voice")

    st.markdown(
        "**Upload a WAV audio file**  \n"
        "(Used for cloud deployment. Real-time mic input is available in local execution.)"
    )

    uploaded_file = st.file_uploader("Upload audio (.wav)", type=["wav"])

    if uploaded_file:
        signal, sample_rate = sf.read(uploaded_file)
        if signal.ndim > 1:
            signal = signal.mean(axis=1)

        features_df = extract_features(signal, sample_rate)
        dataset = load_dataset()

        clf, scaler, le = train_classifier(dataset)
        prediction = clf.predict(scaler.transform(features_df))
        label = le.inverse_transform(prediction)[0]

        st.success(f"Prediction: **{label}**")

        if label.lower() == "human":
            toggle_leds(1)
            play_audio_feedback("The voice is generated by a human")
        else:
            toggle_leds(0)
            play_audio_feedback("The voice is AI generated")

elif section == "Explore Dataset":
    dataset = load_dataset()
    st.write(dataset)
    st.write(dataset.describe())

    fig, ax = plt.subplots()
    dataset["Class"].value_counts().plot(kind="bar", ax=ax)
    st.pyplot(fig)
